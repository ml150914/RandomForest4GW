{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ef95efa5-6228-4007-a3c9-eb3c2f93053e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backend in use: agg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cvmfs/software.igwn.org/conda/envs/igwn-py39/lib/python3.9/site-packages/pandas/core/computation/expressions.py:21: UserWarning: Pandas requires version '2.8.4' or newer of 'numexpr' (version '2.7.3' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n"
     ]
    }
   ],
   "source": [
    "import matplotlib\n",
    "matplotlib.use(\"Agg\")  # Must be the FIRST line\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "plt.rcParams.update({\n",
    "    \"text.usetex\": True,\n",
    "    \"font.family\": \"serif\",\n",
    "})\n",
    "\n",
    "# Confirm backend\n",
    "print(\"Backend in use:\", matplotlib.get_backend())  # must print 'agg'\n",
    "\n",
    "# import modules\n",
    "import numpy as np\n",
    "import seaborn as sns; sns.set()\n",
    "\n",
    "# import the sklearn modules                                                                                                               \n",
    "import sklearn\n",
    "from sklearn.ensemble import RandomForestClassifier,RandomForestRegressor\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, ConfusionMatrixDisplay, RocCurveDisplay, make_scorer, precision_score, recall_score, f1_score, roc_auc_score\n",
    "from sklearn.model_selection import RandomizedSearchCV, train_test_split\n",
    "from sklearn.tree import export_graphviz\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from scipy.stats import randint\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "\n",
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7a417abc-4f47-47f7-9b9b-086f1cc6d576",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the data\n",
    "\n",
    "dfnoise = pd.read_csv('/home/lorenzo.mobilia/PhD-Thesis/pastro-o3-mbta-triggers-paper/RF-codes/data/O3b/noise_no_catalogue.csv', sep = ',')\n",
    "dfinj = pd.read_csv('/home/lorenzo.mobilia/PhD-Thesis/pastro-o3-mbta-triggers-paper/RF-codes/data/O3b/injections.csv', sep = ',')\n",
    "dfEvents_confident = pd.read_csv('/home/lorenzo.mobilia/PhD-Thesis/pastro-o3-mbta-triggers-paper/RF-codes/data/O3b-events/GWTCO3b.csv', delimiter = ',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2314969b-2cf5-4d41-a8fa-256c9b03796f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plots are stored in  /home/lorenzo.mobilia/PhD-Thesis/pastro-o3-mbta-triggers-paper/RF-codes/O3b-results-figs/HL_F_ER_M_Best/\n",
      "Data are stored in  /home/lorenzo.mobilia/PhD-Thesis/pastro-o3-mbta-triggers-paper/RF-codes/O3b-results-data/HL_F_ER_M_Best/\n"
     ]
    }
   ],
   "source": [
    "# Path specifics  \n",
    "TYPE = \"DOUBLE\" # Type of coincidence\n",
    "Ifo = 'HL' # Interferometers\n",
    "F = 'F_ER' # Features\n",
    "M = 'M_Best' # Type of model\n",
    "\n",
    "\n",
    "#Define the features\n",
    "features_inj = [#'index', \n",
    "                'L_snr', 'H_snr','V_snr',#F0\n",
    "                'amplitude', #F9\n",
    "                'L_autochi^2_PQ',\t'H_autochi^2_PQ', #F0\n",
    "                'm1', 'm2', #F1\n",
    "                'mc',\n",
    "                's1z', 's2z', #F2\n",
    "                't_dur', #F3\n",
    "                'nEvents', #F4\n",
    "                'L_ERw', 'H_ERw', #F5\n",
    "                'L_phase',\t'H_phase', #F6\n",
    "                'L_effDist', 'H_effDist', #F7\n",
    "                'Lend_time', 'Hend_time',\n",
    "                'iFAR',\n",
    "                'label',\n",
    "                'gps_time',\n",
    "            ]\n",
    "\n",
    "savefig_path = f'/home/lorenzo.mobilia/PhD-Thesis/pastro-o3-mbta-triggers-paper/RF-codes/O3b-results-figs/{Ifo}_{F}_{M}/'\n",
    "savedata_path = f'/home/lorenzo.mobilia/PhD-Thesis/pastro-o3-mbta-triggers-paper/RF-codes/O3b-results-data/{Ifo}_{F}_{M}/'\n",
    "\n",
    "if(os.path.isdir(savefig_path) == False):\n",
    "    os.makedirs(savefig_path)\n",
    "if(os.path.isdir(savedata_path) == False):\n",
    "    os.makedirs(savedata_path)\n",
    "\n",
    "print('Plots are stored in ',savefig_path )\n",
    "print('Data are stored in ', savedata_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8901ee18-f692-4199-a058-d3a89366c1f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label\n",
      "Noise    76389\n",
      "Inj      76389\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Create balanced dataset\n",
    "dfDataset_filtered1 = dfnoise.sample(n=76389, replace=False, random_state=12) # Dataset for Test - Training\n",
    "#dfDataset_filtered2 = dfDataset_filtered[~dfDataset_filtered.index.isin(dfDataset_filtered1.index)]\n",
    "dfDataset_filtered2 = dfnoise.drop(dfnoise.index) # Dataset for Validation\n",
    "#dfDataset_filtered = dfDataset_filtered\n",
    "\n",
    "# Merge and create the final dataset\n",
    "dataset = pd.concat([dfDataset_filtered1, dfinj], ignore_index=True)\n",
    "print(dataset['label'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cad856f1-af85-476b-b451-080283f4cb06",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cvmfs/software.igwn.org/conda/envs/igwn-py39/lib/python3.9/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\n",
      "/cvmfs/software.igwn.org/conda/envs/igwn-py39/lib/python3.9/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\n"
     ]
    }
   ],
   "source": [
    "# Study the ranking statistics distribution\n",
    "noise_hist = dataset[dataset['label'] == 'Noise']['amplitude']\n",
    "inj_hist = dataset[dataset['label'] == 'Inj']['amplitude']\n",
    "\n",
    "# Define common bin edges (example: 50 bins over combined range)\n",
    "min_val = min(noise_hist.min(), inj_hist.min())\n",
    "max_val = max(noise_hist.max(), inj_hist.max())\n",
    "bins = np.linspace(min_val, max_val, 100)\n",
    "\n",
    "# Create a new figure explicitly\n",
    "plt.figure()\n",
    "\n",
    "# Plot\n",
    "sns.histplot(noise_hist, bins=bins, alpha=0.7, label='Noise', stat = 'count', element = 'step')\n",
    "sns.histplot(inj_hist, bins=bins, alpha=0.5, label='Injections', stat = 'count', element = 'step')\n",
    "\n",
    "plt.legend()\n",
    "plt.yscale('log')\n",
    "plt.xlabel('Ranking statistic', fontsize=15)\n",
    "plt.ylabel('Count', fontsize=15)\n",
    "plt.title('Ranking statistic Noise - Injections Distributions', fontsize=15)\n",
    "\n",
    "plt.savefig(savefig_path + 'amplitude_distribution.png', dpi=300, bbox_inches='tight')\n",
    "plt.close()  # Close the figure to avoid accumulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2b7112f7-a25b-432d-8c5e-444126ab7ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of features to plot\n",
    "exclude_columns = ['label', 'gps_time', 'gps_time_int', 'index', 't_index', 'iFAR ']  # add any others to exclude\n",
    "features = [col for col in dataset.columns if col not in exclude_columns and dataset[col].dtype in ['float64', 'int64']]\n",
    "\n",
    "dataset['m_tot'] = dataset['m1'] + dataset['m2']\n",
    "dataset['s_eff'] = (dataset['m1']*dataset['s1z'] + dataset['m2']*dataset['s2z']) / dataset['m_tot']\n",
    "dataset['q'] = dataset['m2']/dataset['m1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c9145f6e-16d1-4957-ae1f-83177d626b51",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2207569/70219937.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dfDataset['m_tot'] = dataset['m_tot']\n",
      "/tmp/ipykernel_2207569/70219937.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dfDataset['s_eff'] = dataset['s_eff']\n",
      "/tmp/ipykernel_2207569/70219937.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dfDataset['q'] = dataset['q']\n",
      "/tmp/ipykernel_2207569/70219937.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dfDataset['L_ER'] = np.sqrt(1 - dfDataset['L_ERw']) + 0.3\n",
      "/tmp/ipykernel_2207569/70219937.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dfDataset['H_ER'] = np.sqrt(1 - dfDataset['H_ERw']) + 0.3\n",
      "/tmp/ipykernel_2207569/70219937.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dfDataset['dphi'] = dfDataset['H_phase'] - dfDataset['L_phase']\n",
      "/tmp/ipykernel_2207569/70219937.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dfDataset['dt'] = dfDataset['Hend_time'] - dfDataset['Lend_time']\n",
      "/tmp/ipykernel_2207569/70219937.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dfDataset['dD'] = dfDataset['H_effDist'] - dfDataset['L_effDist']\n"
     ]
    }
   ],
   "source": [
    "# Here we work only with Training - Test dataset\n",
    "\n",
    "dfDataset = dataset[features_inj]\n",
    "dfDataset['m_tot'] = dataset['m_tot']\n",
    "dfDataset['s_eff'] = dataset['s_eff']\n",
    "dfDataset['q'] = dataset['q']\n",
    "\n",
    "dfDataset['L_ER'] = np.sqrt(1 - dfDataset['L_ERw']) + 0.3\n",
    "dfDataset['H_ER'] = np.sqrt(1 - dfDataset['H_ERw']) + 0.3\n",
    "\n",
    "dfDataset['dphi'] = dfDataset['H_phase'] - dfDataset['L_phase']\n",
    "dfDataset['dt'] = dfDataset['Hend_time'] - dfDataset['Lend_time']\n",
    "dfDataset['dD'] = dfDataset['H_effDist'] - dfDataset['L_effDist']\n",
    "#dfDataset['mc_rotated'] = dfDataset['mc'] / dfDataset['m_tot']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7d877473-fb9e-4dcc-80f1-fa3a282e9292",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset:\n",
      "Index(['L_snr', 'H_snr', 'L_autochi^2_PQ', 'H_autochi^2_PQ', 'm1', 'm2', 's1z',\n",
      "       's2z', 't_dur', 'nEvents', 'L_ER', 'H_ER', 'dphi', 'dt', 'dD'],\n",
      "      dtype='object')\n",
      "Labels array:\n",
      "label\n",
      "Inj      76389\n",
      "Noise    76389\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Create the X matrix for features and y for the target       \n",
    "X = dfDataset.drop(columns = ['label','gps_time','V_snr','m_tot', 's_eff',\n",
    "                              'iFAR', 'amplitude', 'q', 'mc','L_ERw', 'H_ERw',\n",
    "                              'L_phase', 'H_phase', 'L_effDist', 'H_effDist', 'Lend_time', 'Hend_time'], axis = 1)\n",
    "\n",
    "#X.index.name = 'INDEX'\n",
    "print('Training dataset:')\n",
    "print(X.columns)\n",
    "print('Labels array:')\n",
    "y = pd.DataFrame(dfDataset['label'])\n",
    "print(y.value_counts())\n",
    "\n",
    "# split the test                                                                                                                           \n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,\n",
    "                                                    test_size = 0.3,\n",
    "                                                    random_state=23\n",
    "                                                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4f812080-cf42-43aa-822e-696d31357b64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfrom sklearn.model_selection import GridSearchCV\\nfrom sklearn.metrics import make_scorer, precision_score, recall_score, f1_score\\n\\n# Define the Random Forest model\\nclf = RandomForestClassifier(random_state=42)\\n\\ny_train_array = y_train.values.ravel()\\n\\n# define the grid\\nparam_grid = {\\n    \\'n_estimators\\': [15, 50, 100],\\n    \\'criterion\\': [\\'entropy\\', \\'gini\\'],\\n    \\'max_depth\\': [10, 15, 20],\\n    \\'min_samples_leaf\\': [1, 5, 10],\\n    \\'min_samples_split\\': [2, 5, 10],\\n    \\'max_features\\': [\\'sqrt\\'],\\n}\\n\\n# Define metrics function\\nprecision = make_scorer(precision_score)\\nrecall = make_scorer(recall_score)\\nf1 = make_scorer(f1_score, pos_label=\\'Inj\\')\\n\\n# Perform the grid search using F1 score\\ngrid_search_f1 = GridSearchCV(estimator=clf, param_grid=param_grid, scoring=f1, n_jobs=-1)\\ngrid_search_f1.fit(X_train, y_train_array)\\n\\n# Get the best parameters and scores\\nprint(\"Best parameters (F1):\", grid_search_f1.best_params_)\\nprint(\"Best F1 score:\", grid_search_f1.best_score_)\\n'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Uncomment for grid search\n",
    "\n",
    "\"\"\"\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer, precision_score, recall_score, f1_score\n",
    "\n",
    "# Define the Random Forest model\n",
    "clf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "y_train_array = y_train.values.ravel()\n",
    "\n",
    "# define the grid\n",
    "param_grid = {\n",
    "    'n_estimators': [15, 50, 100],\n",
    "    'criterion': ['entropy', 'gini'],\n",
    "    'max_depth': [10, 15, 20],\n",
    "    'min_samples_leaf': [1, 5, 10],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'max_features': ['sqrt'],\n",
    "}\n",
    "\n",
    "# Define metrics function\n",
    "precision = make_scorer(precision_score)\n",
    "recall = make_scorer(recall_score)\n",
    "f1 = make_scorer(f1_score, pos_label='Inj')\n",
    "\n",
    "# Perform the grid search using F1 score\n",
    "grid_search_f1 = GridSearchCV(estimator=clf, param_grid=param_grid, scoring=f1, n_jobs=-1)\n",
    "grid_search_f1.fit(X_train, y_train_array)\n",
    "\n",
    "# Get the best parameters and scores\n",
    "print(\"Best parameters (F1):\", grid_search_f1.best_params_)\n",
    "print(\"Best F1 score:\", grid_search_f1.best_score_)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "700a7c3a-6bd5-4373-bf4d-5ea533bedc4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2207569/668008965.py:20: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  clf.fit(X_train, y_train)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability classes:  ['Inj' 'Noise']\n",
      "              ps     pTerr\n",
      "118522  0.999383  0.000617\n",
      "85137   0.989543  0.010457\n",
      "147977  0.999997  0.000003\n",
      "65697   0.005688  0.994312\n",
      "3201    0.024163  0.975837\n",
      "...          ...       ...\n",
      "6621    0.103349  0.896651\n",
      "99122   0.944514  0.055486\n",
      "100555  1.000000  0.000000\n",
      "7221    0.010434  0.989566\n",
      "23075   0.009590  0.990410\n",
      "\n",
      "[45834 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Define and fit the classifier\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators = 100,\n",
    "     #bootstrap=False, # added\n",
    "     bootstrap=True,\n",
    "     random_state=52,\n",
    "     n_jobs =  -1,\n",
    "     criterion =  'entropy',\n",
    "     max_features =  'sqrt',\n",
    "     max_depth =  12,\n",
    "     #min_impurity_decrease=0.00005, # added\n",
    "     min_samples_split= 5,\n",
    "     min_samples_leaf = 1,\n",
    "     #max_leaf_nodes =  8,\n",
    "     #ccp_alpha=0.00005,\n",
    "     #class weight\n",
    "     #class_weight= {'Noise': 1, 'Inj': 2}\n",
    "     )\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "print('Probability classes: ',clf.classes_)                                                                    \n",
    "y_pred_prob = clf.predict_proba(X_test)\n",
    "\n",
    "#define the dataframe for the probabilities\n",
    "dfprobs = pd.DataFrame(y_pred_prob, columns = ['ps', 'pTerr'])\n",
    "dfprobs.index = X_test.index\n",
    "print(dfprobs)\n",
    "\n",
    "#create the dataframe to better manage the data\n",
    "dfX_train = pd.DataFrame(X_train)\n",
    "dfy_train = pd.DataFrame(y_train)\n",
    "dfX_test = pd.DataFrame(X_test)\n",
    "dfy_test = pd.DataFrame(y_test)\n",
    "\n",
    "# Create the resulting dataset for test\n",
    "dfy_pred_prob = pd.DataFrame(y_pred_prob)\n",
    "test_dataset = pd.merge(dfX_test, dfy_test, left_index=True, right_index=True, how='inner')\n",
    "#print(len(test_dataset))\n",
    "#print(test_dataset['label'].value_counts())\n",
    "\n",
    "# Add final informations\n",
    "df_final_test = pd.merge(test_dataset, dfprobs, left_index=True, right_index=True, how='inner')\n",
    "dfRFTriggers = df_final_test\n",
    "dfRFTriggers['amplitude'] = dataset['amplitude']\n",
    "dfRFTriggers['iFAR'] = dataset['iFAR']\n",
    "dfRFTriggers['gps'] = dataset['gps_time']\n",
    "\n",
    "# Separate noise and injection \n",
    "dfRFTriggers_inj = dfRFTriggers[dfRFTriggers['label'] == 'Inj']\n",
    "dfRFTriggers_noise = dfRFTriggers[dfRFTriggers['label'] == 'Noise']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "80ecff71-6265-475e-991e-f65e4c90de0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cvmfs/software.igwn.org/conda/envs/igwn-py39/lib/python3.9/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\n",
      "/cvmfs/software.igwn.org/conda/envs/igwn-py39/lib/python3.9/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\n"
     ]
    }
   ],
   "source": [
    "# Plot the ps distribution\n",
    "# Get both data arrays\n",
    "ps_noise = dfRFTriggers_noise['ps']\n",
    "ps_inj = dfRFTriggers_inj['ps']\n",
    "\n",
    "# Define common bins across both datasets\n",
    "min_val = min(ps_noise.min(), ps_inj.min())\n",
    "max_val = max(ps_noise.max(), ps_inj.max())\n",
    "bins = np.linspace(min_val, max_val, 100)\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "# Plot using consistent bins\n",
    "sns.histplot(ps_noise, bins=bins, alpha=0.5, label='Noise', stat='count', element='step')\n",
    "sns.histplot(ps_inj, bins=bins, label='Injections', stat='count', element='step')\n",
    "\n",
    "# Formatting\n",
    "plt.yscale('log')\n",
    "plt.legend()\n",
    "plt.xlabel(r'$p_s$', fontsize=15)\n",
    "plt.ylabel('Count', fontsize=15)\n",
    "plt.title(r'$p_s$ Injections vs Noise Distribution', fontsize=15)\n",
    "plt.savefig(savefig_path + 'ps_distribution.png', dpi=300, bbox_inches='tight')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9919d02a-94df-464a-960d-2de7b3586f41",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2207569/2671188877.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dfRFTriggers_inj['ps_lim'] = np.log(dfRFTriggers_inj['ps'] / (1 - dfRFTriggers_inj['ps']))\n",
      "/tmp/ipykernel_2207569/2671188877.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dfRFTriggers_noise['ps_lim'] = np.log(dfRFTriggers_noise['ps'] / (1 - dfRFTriggers_noise['ps']))\n",
      "/tmp/ipykernel_2207569/2671188877.py:9: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  dfRFTriggers_inj['ps_lim'].replace([np.inf], m1, inplace=True)\n",
      "/tmp/ipykernel_2207569/2671188877.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dfRFTriggers_inj['ps_lim'].replace([np.inf], m1, inplace=True)\n",
      "/tmp/ipykernel_2207569/2671188877.py:13: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  dfRFTriggers_noise['ps_lim'].replace([np.inf], m2, inplace=True)\n",
      "/tmp/ipykernel_2207569/2671188877.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dfRFTriggers_noise['ps_lim'].replace([np.inf], m2, inplace=True)\n",
      "/tmp/ipykernel_2207569/2671188877.py:14: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  dfRFTriggers_noise['ps_lim'].replace([-np.inf], min2, inplace=True)\n",
      "/tmp/ipykernel_2207569/2671188877.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dfRFTriggers_noise['ps_lim'].replace([-np.inf], min2, inplace=True)\n",
      "/cvmfs/software.igwn.org/conda/envs/igwn-py39/lib/python3.9/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\n",
      "/cvmfs/software.igwn.org/conda/envs/igwn-py39/lib/python3.9/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\n"
     ]
    }
   ],
   "source": [
    "# Now we apply the logit transformation - ensure no inf values\n",
    "\n",
    "# Ensure no inf values\n",
    "dfRFTriggers_inj['ps_lim'] = np.log(dfRFTriggers_inj['ps'] / (1 - dfRFTriggers_inj['ps']))\n",
    "dfRFTriggers_noise['ps_lim'] = np.log(dfRFTriggers_noise['ps'] / (1 - dfRFTriggers_noise['ps']))\n",
    "\n",
    "# Replace inf and -inf with finite max/min values\n",
    "m1 = dfRFTriggers_inj.loc[np.isfinite(dfRFTriggers_inj['ps_lim']), 'ps_lim'].max()\n",
    "dfRFTriggers_inj['ps_lim'].replace([np.inf], m1, inplace=True)\n",
    "\n",
    "m2 = dfRFTriggers_noise.loc[np.isfinite(dfRFTriggers_noise['ps_lim']), 'ps_lim'].max()\n",
    "min2 = dfRFTriggers_noise.loc[np.isfinite(dfRFTriggers_noise['ps_lim']), 'ps_lim'].min()\n",
    "dfRFTriggers_noise['ps_lim'].replace([np.inf], m2, inplace=True)\n",
    "dfRFTriggers_noise['ps_lim'].replace([-np.inf], min2, inplace=True)\n",
    "\n",
    "# Define common bins over both datasets\n",
    "combined = pd.concat([dfRFTriggers_inj['ps_lim'], dfRFTriggers_noise['ps_lim']])\n",
    "bins = np.linspace(combined.min(), combined.max(), 100)\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "# Plot histograms\n",
    "sns.histplot(dfRFTriggers_noise['ps_lim'], bins=bins, label='Noise', stat='count', element='step', alpha=0.5)\n",
    "sns.histplot(dfRFTriggers_inj['ps_lim'], bins=bins, label='Injections', stat='count', element='step')\n",
    "\n",
    "# Formatting\n",
    "plt.yscale('log')\n",
    "plt.xlabel(r'$\\tilde{p}_s$')\n",
    "plt.ylabel('Occurrencies')\n",
    "plt.legend()\n",
    "plt.title(r'Distribution of $\\tilde{p}_s$')\n",
    "plt.tight_layout()\n",
    "plt.savefig(savefig_path + 'ps_lim_distribution.png', dpi=300, bbox_inches='tight')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ed2518af-6652-4e70-b836-3583669843bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now compute the KDE for the pAstro\n",
    "\n",
    "from sklearn.neighbors import KernelDensity\n",
    "\n",
    "values_inj = dfRFTriggers_inj['ps_lim'].values.reshape(-1,1) # create trhe right format for the data\n",
    "\n",
    "# Choose the binning\n",
    "binning_noise = 0.6\n",
    "binning_inj =0.8\n",
    "\n",
    "kde_inj = KernelDensity(bandwidth=binning_inj, kernel='gaussian') # Define the kde with banwidth and kernel\n",
    "kde_inj.fit(values_inj) # fit with the values\n",
    "\n",
    "x = np.linspace(min(dfRFTriggers_inj['ps_lim']), max(dfRFTriggers_inj['ps_lim']), 25).reshape(-1,1) # take some random values from the data\n",
    "\n",
    "# Estimate the density for the range of values\n",
    "log_density_inj = kde_inj.score_samples(x) # Comput the log likelihood oe each sample under the model\n",
    "density_inj = np.exp(log_density_inj)\n",
    "\n",
    "values_noise = dfRFTriggers_noise['ps_lim'].values.reshape(-1,1) # create trhe right format for the data\n",
    "\n",
    "kde_noise = KernelDensity(bandwidth=binning_noise, kernel='gaussian') # Define the kde with banwidth and kernel\n",
    "kde_noise.fit(values_noise) # fit with the values\n",
    "\n",
    "\n",
    "y = np.linspace(min(dfRFTriggers_noise['ps_lim']), max(dfRFTriggers_noise['ps_lim']), 25).reshape(-1,1) # take some random values from the data\n",
    "\n",
    "# Estimate the density for the range of values\n",
    "log_density_noise = kde_noise.score_samples(y) # Comput the log likelihood oe each sample under the model\n",
    "density_noise = np.exp(log_density_noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9441aba2-9526-4e13-9812-fc5059fd57ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cvmfs/software.igwn.org/conda/envs/igwn-py39/lib/python3.9/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\n",
      "/cvmfs/software.igwn.org/conda/envs/igwn-py39/lib/python3.9/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\n",
      "/cvmfs/software.igwn.org/conda/envs/igwn-py39/lib/python3.9/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\n",
      "/cvmfs/software.igwn.org/conda/envs/igwn-py39/lib/python3.9/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\n",
      "/cvmfs/software.igwn.org/conda/envs/igwn-py39/lib/python3.9/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\n",
      "/cvmfs/software.igwn.org/conda/envs/igwn-py39/lib/python3.9/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\n"
     ]
    }
   ],
   "source": [
    "# Plt the KDE\n",
    "\n",
    "# Flatten KDE input arrays\n",
    "x = x.flatten()\n",
    "y = y.flatten()\n",
    "\n",
    "# Combine both ps_lim arrays to define shared bin edges\n",
    "ps_lim_inj = dfRFTriggers_inj['ps_lim']\n",
    "ps_lim_noise = dfRFTriggers_noise['ps_lim']\n",
    "combined = np.concatenate([ps_lim_inj, ps_lim_noise])\n",
    "bins = np.linspace(combined.min(), combined.max(), 25)\n",
    "\n",
    "# Create figure and twin axes\n",
    "fig = plt.figure(figsize=(15, 10))\n",
    "ax1 = fig.add_subplot(111)\n",
    "ax2 = ax1.twinx()\n",
    "\n",
    "# Plot histograms with shared bins and no auto-legend\n",
    "sns.histplot(ps_lim_noise, bins=bins, alpha=0.3, ax=ax1, stat=\"density\", color='b', label=None)\n",
    "sns.histplot(ps_lim_inj, bins=bins, alpha=0.3, ax=ax1, stat=\"density\", color='r', label=None)\n",
    "\n",
    "# Plot KDEs (lines) with no auto-legend\n",
    "sns.lineplot(x=x, y=density_inj, color='r', label=None)\n",
    "sns.lineplot(x=y, y=density_noise, color='b', label=None)\n",
    "\n",
    "# Manually define legend handles\n",
    "from matplotlib.lines import Line2D\n",
    "from matplotlib.patches import Patch\n",
    "\n",
    "custom_legend = [\n",
    "    Line2D([0], [0], color='r', lw=2, label='Injections PDF'),\n",
    "    Line2D([0], [0], color='b', lw=2, label='Noise PDF'),\n",
    "    Patch(facecolor='r', alpha=0.3, label='Injections (hist)'),\n",
    "    Patch(facecolor='b', alpha=0.3, label='Noise (hist)'),\n",
    "]\n",
    "# Ticks dimension\n",
    "ax1.tick_params(axis='both', labelsize=25)  # ticks for ax1\n",
    "ax2.tick_params(axis='both', labelsize=25)  # ticks for ax2\n",
    "\n",
    "# Axis labels and title\n",
    "ax1.set_xlabel(r'$\\tilde{p}_s$',  fontsize=30)\n",
    "ax1.set_ylabel('Histogram Density',  fontsize=30)\n",
    "ax2.set_ylabel('PDF Density',  fontsize=30)\n",
    "plt.title('PDF via KDE and Histogram',  fontsize=40)\n",
    "\n",
    "# External single legend\n",
    "ax1.legend(handles=custom_legend, bbox_to_anchor=(1.05, 1), loc='upper left', fontsize=20)\n",
    "\n",
    "# Save and display\n",
    "plt.tight_layout()\n",
    "plt.savefig(savefig_path + 'pdf_final.png', dpi=300, bbox_inches='tight')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2330f2eb-a7db-4bc5-aae3-12c6f4d43aa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prior for Noise (RATE 6 months) 129106\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2207569/1019813341.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dfRFTriggers_inj['pAstro_rw'] = pAstro_rw_signals\n"
     ]
    }
   ],
   "source": [
    "# Now compute the pAstro - Injections\n",
    "\n",
    "values = np.array(dfRFTriggers_inj['ps_lim']) # read the ps_lim\n",
    "ranks = values.reshape(-1, 1) # reshape it\n",
    "#ranks_list = ranks.flatten().tolist() # flatten to a list\n",
    "\n",
    "log_score_event = kde_inj.score_samples(ranks) # assign the score\n",
    "score_event =  np.exp(log_score_event) # p(signal|ps_lim)\n",
    "\n",
    "log_score_noise = kde_noise.score_samples(ranks)\n",
    "score_noise = np.exp(log_score_noise) # p(noise|ps_lim)\n",
    "\n",
    "# priors\n",
    "Lambda1 = 36\n",
    "Lambda0 = len(dfnoise)\n",
    "print('Prior for Noise (RATE 6 months)', len(dfnoise))\n",
    "\n",
    "# Now compute the pAstro from ps_lim\n",
    "\n",
    "pAstro_rw_signals =[]\n",
    "for rank, score_s, score_n in zip(ranks, score_event, score_noise):\n",
    "   S = Lambda1*score_s\n",
    "   N = Lambda0*score_n\n",
    "   value = S/(S + N)\n",
    "   pAstro_rw_signals.append(value.tolist())\n",
    "\n",
    "dfRFTriggers_inj['pAstro_rw'] = pAstro_rw_signals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d31e3483-9f51-4778-a4bc-1d991bddbca8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2207569/3076381244.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dfRFTriggers_noise['pAstro_rw'] = pAstro_rw_noise\n"
     ]
    }
   ],
   "source": [
    "# Now compute the pAstro - Noise\n",
    "\n",
    "values = np.array(dfRFTriggers_noise['ps_lim'])\n",
    "ranks = values.reshape(-1, 1)\n",
    "\n",
    "log_score_event = kde_inj.score_samples(ranks)\n",
    "score_event =  np.exp(log_score_event)\n",
    "\n",
    "log_score_noise = kde_noise.score_samples(ranks)\n",
    "score_noise = np.exp(log_score_noise)\n",
    "\n",
    "pAstro_rw_noise =[]\n",
    "for rank, score_s, score_n in zip(ranks, score_event, score_noise):\n",
    "   S = Lambda1*score_s\n",
    "   N = Lambda0*score_n\n",
    "   value = S/(S + N)\n",
    "   pAstro_rw_noise.append(value.tolist())\n",
    "\n",
    "dfscore_event_noise_triggers = pd.DataFrame(score_event)\n",
    "dfscore_noise_noise_triggers = pd.DataFrame(score_noise)\n",
    "\n",
    "dfRFTriggers_noise['pAstro_rw'] = pAstro_rw_noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "698057d7-cf63-4009-847c-590c0d2df8fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the result\n",
    "\n",
    "plt.figure()\n",
    "plt.scatter(dfRFTriggers_inj['amplitude'], dfRFTriggers_inj['pAstro_rw'], c = 'darkorange', s = 1, label = 'Injections')\n",
    "plt.scatter(dfRFTriggers_noise['amplitude'], dfRFTriggers_noise['pAstro_rw'], c = 'b', s = 3, label = 'Noise')\n",
    "plt.xlabel('Ranking statistic')\n",
    "plt.ylabel(r'$p_\\mathrm{astro}^{ps}$', fontsize = 15)\n",
    "plt.title(r'$p_\\mathrm{astro}^{ps}$ - ranking statistics', fontsize = 15)\n",
    "plt.legend()\n",
    "plt.savefig(savefig_path + 'pAstro_ps_amplitude_injections.png', dpi=300, bbox_inches='tight')\n",
    "plt.legend()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0571ba60-0665-471b-990c-73d107aaaf86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the the RoC function \n",
    "def RoC(df1, df2, column, var, label, save = True, thr=0.005, color = 'b'):\n",
    "    if column not in df1.columns:\n",
    "        raise ValueError(f\"Column '{column}' not found in the DataFrame.\")\n",
    "# Drop missing values and sort unique values of the column                                                                                                       \n",
    "    data1 = df1[column].dropna()\n",
    "    data2 = df2[column].dropna()\n",
    "    #thresholds = np.sort(data.unique())                                                                                                                             \n",
    "    thresholds = np.arange(min(data1),max(data1), thr)\n",
    "\n",
    "    # Calculate the cumulative distribution                                                                                                                          \n",
    "    count_above_threshold1 = [np.sum(data1 > threshold) / len(data1) for threshold in thresholds]\n",
    "    count_above_threshold2 =  [np.sum(data2 > threshold) / len(data2) for threshold in thresholds]\n",
    "\n",
    "    # Create a DataFrame for the cumulative distribution                                                                                                             \n",
    "    cumulative_df = pd.DataFrame({\n",
    "        'threshold': thresholds,\n",
    "        'count_above_threshold1': count_above_threshold1,\n",
    "        'count_above_threshold2': count_above_threshold2\n",
    "    })\n",
    "\n",
    "    if save:\n",
    "        cumulative_df.to_csv(path_data + f'/{var}_RoC_{label}.csv', index=False)\n",
    "\n",
    "    # Plot the cumulative distribution                                                                                                                               \n",
    "    plt.plot(cumulative_df['count_above_threshold1'], cumulative_df['count_above_threshold2'], label=label, c = color, linewidth=3.0)\n",
    "    plt.yscale('log')\n",
    "    plt.xscale('log')\n",
    "\n",
    "    return cumulative_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e78dfbd0-1d4b-41f7-a614-90085164d048",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/lorenzo.mobilia/PhD-Thesis/pastro-o3-mbta-triggers-paper/RF-codes/O3b-results-figs/HL_F_ER_M_Best/\n"
     ]
    }
   ],
   "source": [
    "# Compute the Roc function  \n",
    "plt.figure()\n",
    "RoC(dfRFTriggers_noise, dfRFTriggers_inj, 'ps', 'Roc', r'$p_s$', thr = 0.0001, color = 'r', save = False)\n",
    "RoC(dfRFTriggers_noise,dfRFTriggers_inj, 'amplitude', 'Roc', 'Ranking statistic', thr = 0.005, save = False, color= 'steelblue')\n",
    "plt.legend()\n",
    "plt.grid(True, which='both')\n",
    "plt.ylabel('Nd (density)', fontsize=15)\n",
    "plt.xlabel(r'$\\alpha$', fontsize=15)\n",
    "plt.savefig(savefig_path + 'RoC_O3a.png', dpi=300, bbox_inches='tight')\n",
    "plt.close()\n",
    "print(savefig_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "babf3692-57fa-40fa-b179-837854ee4400",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now study the pAstro for events in the catalogue\n",
    "\n",
    "events = dfEvents_confident#dfDataset_events_complete\n",
    "events['label'] = 'event'\n",
    "\n",
    "# fill in the added features (if you want to use them)\n",
    "events['L_ER'] = np.sqrt(1 - events['L_ERw']) + 0.3\n",
    "events['H_ER'] = np.sqrt(1 - events['H_ERw']) + 0.3\n",
    "events['dphi'] = events['H_phase'] - events['L_phase']\n",
    "events['dt'] = events['Hend_time'] - events['Lend_time']\n",
    "events['dD'] = events['H_effDist'] - events['L_effDist']\n",
    "events['m_tot'] = events['m1'] + events['m2']\n",
    "events['s_eff'] = (events['m1']*events['s1z'] + events['m2']*events['s2z']) / events['m_tot']\n",
    "\n",
    "y_evt = events['label'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2de5f755-719f-40ce-ad48-49fbf23ebf42",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_event_test = events.drop(columns = ['Unnamed: 0','label','gps_time', 'mc', 'm_tot', 's_eff','V_snr',\n",
    "                               'iFAR', 'amplitude',\n",
    "                              'L_phase', 'H_phase', 'L_effDist', 'H_effDist', 'Lend_time', 'Hend_time','L_ERw', 'H_ERw',\n",
    "                               'gps_time', 'commonName', 'GPS', 'pAstroMbta', 'GPS_int', 'gps_time_int'], axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f57ecfa8-60c1-4a24-9859-6a8eabb94b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now apply the classifier\n",
    "y_pred_prob_events = clf.predict_proba(X_event_test)\n",
    "dfy_pred_prob_events = pd.DataFrame(y_pred_prob_events, columns = ['ps', 'pTerr'])\n",
    "\n",
    "# Compactify the result\n",
    "dfX_test_events = pd.DataFrame(X_event_test)\n",
    "dfy_test_events = pd.DataFrame(y_evt)\n",
    "\n",
    "test_dataset_events = pd.merge(dfX_test_events, dfy_test_events, left_index=True, right_index=True, how='inner')\n",
    "dfRFTriggers_events= pd.merge(test_dataset_events, dfy_pred_prob_events, left_index=True, right_index=True, how='inner')\n",
    "\n",
    "# fill in the dataframe\n",
    "dfRFTriggers_events.index = dfEvents_confident.index #dfDataset_events_complete.index\n",
    "dfRFTriggers_events['p_astro'] = dfEvents_confident['pAstroMbta']\n",
    "dfRFTriggers_events['amplitude'] = dfEvents_confident['amplitude']\n",
    "dfRFTriggers_events['iFAR'] = dfEvents_confident['iFAR']\n",
    "dfRFTriggers_events['commonName'] = dfEvents_confident['commonName']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cde60e39-12ff-48c1-a8cb-2d6a4fbccfda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n",
      "16\n",
      "16\n",
      "    pAstro_rw    ps_lim\n",
      "0    0.999997  8.238434\n",
      "1    0.999997  8.238434\n",
      "2    0.126283  4.786646\n",
      "3    0.999997  8.238434\n",
      "4    0.870005  6.584791\n",
      "5    0.999997  8.238434\n",
      "6    0.999997  8.238434\n",
      "7    0.016826  2.846170\n",
      "8    0.707564  6.338005\n",
      "9    0.127727  4.818663\n",
      "10   0.999997  8.238434\n",
      "11   0.999997  8.238434\n",
      "12   0.000234 -0.149033\n",
      "13   0.999997  8.238434\n",
      "14   0.999597  7.613505\n",
      "15   0.001238  1.111607\n"
     ]
    }
   ],
   "source": [
    "# Now compute the ps_lim for the events\n",
    "dfRFTriggers_events['ps_lim'] = np.log(dfRFTriggers_events['ps'] / (1 - dfRFTriggers_events['ps']))\n",
    "\n",
    "m1 = dfRFTriggers_events.loc[dfRFTriggers_events['ps_lim'] != np.inf, 'ps_lim'].max()\n",
    "dfRFTriggers_events['ps_lim'] = dfRFTriggers_events['ps_lim'].replace([np.inf],m1)\n",
    "\n",
    "# Compute pAstro for real Triggers\n",
    "\n",
    "values = np.array(dfRFTriggers_events['ps_lim'])\n",
    "ranks = values.reshape(-1, 1)\n",
    "ranks_list = ranks.flatten().tolist()\n",
    "\n",
    "log_score_event = kde_inj.score_samples(ranks)\n",
    "score_event =  np.exp(log_score_event)\n",
    "\n",
    "\n",
    "log_score_noise = kde_noise.score_samples(ranks)\n",
    "score_noise = np.exp(log_score_noise)\n",
    "\n",
    "\n",
    "Lambda1 = 36\n",
    "#Lambda0 = len(noise)\n",
    "print(len(score_event))\n",
    "print(len(score_noise))\n",
    "print(len(ranks_list))\n",
    "\n",
    "\n",
    "pAstro_rw_signals =[]\n",
    "for rank, score_s, score_n in zip(ranks, score_event, score_noise):\n",
    "   S = Lambda1*score_s\n",
    "   N = Lambda0*score_n\n",
    "   value = S/(S + N)\n",
    "   pAstro_rw_signals.append(value.tolist())\n",
    "\n",
    "\n",
    "dfRFTriggers_events['pAstro_rw'] = pAstro_rw_signals\n",
    "print(dfRFTriggers_events[['pAstro_rw', 'ps_lim']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "23e46b7c-d249-470f-9226-09180823d21c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the final result\n",
    "\n",
    "plt.figure()\n",
    "plt.scatter(dfRFTriggers_events['amplitude'], dfRFTriggers_events['pAstro_rw'], label = r'Events - $p_\\mathrm{astro}^{ps}$', s = 55)\n",
    "plt.scatter(dfRFTriggers_events['amplitude'], dfRFTriggers_events['p_astro'], label = r'Events - $p_\\mathrm{astro}$', color = 'r', marker='x', s = 55)\n",
    "plt.legend()\n",
    "plt.title(r'$p_\\mathrm{astro}^{ps}$ - $p_\\mathrm{astro}$ - ranking statistics O3b Events')\n",
    "plt.xlabel('ranking statistics')\n",
    "plt.ylabel(r'$p_\\mathrm{astro}$')\n",
    "plt.ylim([-0.1,1.1])\n",
    "# Plot a horizontal line at y = 25\n",
    "plt.axhline(y=0.5, color='g', linestyle='-.')\n",
    "plt.savefig(savefig_path + 'pAstro_ps_amplitude_O3bEvents_hihglight.png', dpi=300, bbox_inches='tight')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1f3c1d2-b9ba-47b3-8f14-ec3fee95e0c6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "igwn-py39",
   "language": "python",
   "name": "igwn-py39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
